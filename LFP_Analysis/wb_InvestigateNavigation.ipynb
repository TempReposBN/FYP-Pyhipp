{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from load_data import get_data\n",
    "from processing_helpers import get_power_spec, get_peak_fits, get_navigation_segments\n",
    "from tally_helper import TallyWindow\n",
    "# from plot_window import plot_processing\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import DataProcessingTools as DPT\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from fooof import FOOOF\n",
    "from ipywidgets import widgets, HBox, VBox, Output\n",
    "from scipy.stats import sem, f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables to store the session data\n",
    "lfp_df = pd.DataFrame()\n",
    "ch_num_list = []\n",
    "lfp_mne = []\n",
    "session_start_time = 0\n",
    "markers = []\n",
    "timeStamps = []\n",
    "sampling_frequency = 0\n",
    "segments_df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(day):\n",
    "    \"\"\"\n",
    "    Load LFP data for a given day.\n",
    "    \"\"\"\n",
    "    global lfp_df, ch_num_list, lfp_mne, session_start_time, markers, timeStamps, sampling_frequency\n",
    "    print(f\"Loading data for {day}...\")\n",
    "    lfp_df, ch_num_list, lfp_mne, session_start_time, markers, timeStamps, sampling_frequency = get_data(day)\n",
    "\n",
    "    if lfp_df is not None:\n",
    "        print(f\"Loaded {len(ch_num_list)} channels.\")\n",
    "        print(lfp_df.head())\n",
    "    else:\n",
    "        print(\"Failed to load data.\")\n",
    "\n",
    "\n",
    "def load_pkl(file_path):\n",
    "    \"\"\"\n",
    "    Load segments DataFrame from a Pickle file.\n",
    "    \"\"\"\n",
    "    global segments_df\n",
    "    try:\n",
    "        with open(file_path, 'rb') as file:\n",
    "            segments_df = pkl.load(file)\n",
    "        print(f\"Data successfully loaded from {file_path}\")\n",
    "        print(f\"Loaded data has {segments_df.shape[0]} rows and {segments_df.shape[1]} columns.\")\n",
    "        print(segments_df.head())\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load data: {str(e)}\")\n",
    "\n",
    "\n",
    "def save_pkl(file_path):\n",
    "    \"\"\"\n",
    "    Save the current segments DataFrame to a Pickle file.\n",
    "    \"\"\"\n",
    "    if segments_df.empty:\n",
    "        print(\"No data available to export.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        if not file_path.endswith('.pkl'):\n",
    "            file_path += '.pkl'\n",
    "\n",
    "        with open(file_path, 'wb') as file:\n",
    "            pkl.dump(segments_df, file)\n",
    "        print(f\"Data successfully exported to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to export data: {str(e)}\")\n",
    "\n",
    "\n",
    "def get_segment(window_size, method='welch', max_n_peaks=3, peak_threshold=2, peak_fit_range=[1,12]):\n",
    "    \"\"\"\n",
    "    Extract segments from the LFP data using the specified window size.\n",
    "    \"\"\"\n",
    "    global segments_df\n",
    "\n",
    "    if lfp_df.empty or not markers or not timeStamps:\n",
    "        print(\"Please load data before extracting segments.\")\n",
    "        return\n",
    "\n",
    "    segments_df = get_navigation_segments(lfp_df, markers, timeStamps, window_size=window_size)\n",
    "    print(f\"Extracted {len(segments_df)} segments.\")\n",
    "\n",
    "    frequencies = []\n",
    "    psd_list = []\n",
    "    p_stds_l = []\n",
    "    p_means_l = []\n",
    "    peak_gauss_l = []\n",
    "    flat_spec_l = []\n",
    "    flat_spec_og_l = []\n",
    "    ap_fit_og_l = []\n",
    "    peaks_l, peak_freqs_l = [], []\n",
    "\n",
    "    count = 0\n",
    "    segments_list = segments_df['segment'].values  # Convert df to array for faster processing\n",
    "\n",
    "    for segment in segments_list:\n",
    "        freq, psd = get_power_spec(segment, sampling_frequency, method=method)\n",
    "        frequencies.append(freq)\n",
    "\n",
    "\n",
    "        psd, ap_fit_og, flat_spec_og, p_stds, p_means, peak_gauss, flat_specs, peaks, peak_freqs= get_peak_fits(psd, freq, peak_fit_range, max_n_peaks=max_n_peaks, peak_threshold=peak_threshold)\n",
    "        psd_list.append(psd)\n",
    "        p_stds_l.append(p_stds)\n",
    "        p_means_l.append(p_means)\n",
    "        peak_gauss_l.append(peak_gauss)\n",
    "        flat_spec_l.append(flat_specs)\n",
    "        flat_spec_og_l.append(flat_spec_og)\n",
    "        ap_fit_og_l.append(ap_fit_og)\n",
    "        peaks_l.append(peaks)\n",
    "        peak_freqs_l.append(peak_freqs)\n",
    "\n",
    "        count += 1\n",
    "        print(f\"Processed segment {count}\")\n",
    "\n",
    "    segments_df['psd'] = psd_list\n",
    "    segments_df['freq'] = frequencies\n",
    "    segments_df['peak_stds'] = p_stds_l\n",
    "    segments_df['peak_means'] = p_means_l\n",
    "    segments_df['peak_gauss'] = peak_gauss_l\n",
    "    segments_df['flat_specs'] = flat_spec_l\n",
    "    segments_df['flat_spec_og'] = flat_spec_og_l\n",
    "    segments_df['ap_fit_og'] = ap_fit_og_l\n",
    "    segments_df['peaks'] = peaks_l\n",
    "    segments_df['peak_freqs'] = peak_freqs_l\n",
    "    print(\"Segments processed successfully.\")\n",
    "\n",
    "def show_tally():\n",
    "    \"\"\"\n",
    "    Display tally information for the segments DataFrame.\n",
    "    \"\"\"\n",
    "    if segments_df.empty:\n",
    "        print(\"Please generate segments before viewing the tally.\")\n",
    "        return\n",
    "\n",
    "    # Example of tally logic; customize as needed\n",
    "    print(\"Tally of segments by channel:\")\n",
    "    print(segments_df.groupby('channel').size())\n",
    "    TallyWindow(segments_df, ch_num_list).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for 20181105...\n",
      "Creating RawArray with float64 data, n_channels=26, n_times=5496020\n",
      "    Range : 0 ... 5496019 =      0.000 ...  5496.019 secs\n",
      "Ready.\n",
      "Loaded 26 channels.\n",
      "  channel                                           lfp_data\n",
      "0     009  [-15.689277, -63.415035, -97.32542, -110.48099...\n",
      "1     019  [-7.3521805, -22.254305, -32.18146, -35.23267,...\n",
      "2     021  [-7.631544, -1.5259957, 3.660045, 8.1869755, 1...\n",
      "3     022  [-56.752617, -77.27964, -92.39461, -100.60819,...\n",
      "4     023  [32.315643, 41.446926, 46.777287, 46.48198, 41...\n"
     ]
    }
   ],
   "source": [
    "# Load Raw Data\n",
    "day = \"20181105\"\n",
    "load_data(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 0 segments.\n",
      "Segments processed successfully.\n"
     ]
    }
   ],
   "source": [
    "# Extract segments with a specific window size and process\n",
    "window_size = 7000  # e.g., 1000 ms\n",
    "peak_fit_range = [1,14]\n",
    "get_segment(window_size, method='welch', max_n_peaks=3, peak_threshold=1.76, peak_fit_range=peak_fit_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_pkl(f\"Data Processed/{day}_1s_welch.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seg_len = 1\n",
    "# method = \"welch\"\n",
    "\n",
    "# path = f\"Data Processed/{day}_{seg_len}s_{method}_.pkl\"\n",
    "\n",
    "# if os.path.exists(path):    \n",
    "#     # Load segments from a Pickle file    \n",
    "#     load_pkl(path)\n",
    "\n",
    "# else: \n",
    "#     # Save the processed segments to a Pickle file\n",
    "#     save_pkl(path)\n",
    "\n",
    "# # Show tally information\n",
    "# show_tally()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate interactive plotting in Jupyter Notebook\n",
    "%matplotlib widget\n",
    "\n",
    "# Initial index\n",
    "current_index = [0]\n",
    "\n",
    "# Create the figure and axis\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15, 4))\n",
    "ax = ax.flatten()\n",
    "\n",
    "# Function to update the plot\n",
    "def update_plot(index):\n",
    "    ch = segments_df.iloc[index][\"channel\"]\n",
    "    start_pos = segments_df.iloc[index][\"start_position\"]\n",
    "    cue_onset = segments_df.iloc[index][\"cue_onset\"]\n",
    "\n",
    "    ax[0].clear()\n",
    "    ax[0].plot(segments_df.iloc[index]['segment'])\n",
    "    ax[0].set_title(\"Raw Data\")\n",
    "    ax[0].set_xlabel(\"Time (ms)\")\n",
    "    ax[0].set_ylabel(\"mV\")\n",
    "\n",
    "    ax[1].clear()\n",
    "    ax[1].plot(segments_df.iloc[index]['psd'][1:150])\n",
    "    ax[1].set_title(\"Power Spectral Density\")\n",
    "    ax[1].set_xlabel(\"Frequency Bin\")\n",
    "    ax[1].set_ylabel(\"Power (log scale)\")\n",
    "\n",
    "    ax[2].clear()\n",
    "    ax[2].plot(segments_df.iloc[index]['psd'][1:150])\n",
    "    ax[2].plot(segments_df.iloc[index]['flat_spec_og'][1:150])\n",
    "    ax[2].plot(segments_df.iloc[index]['ap_fit_og'][1:150])\n",
    "    ax[2].set_title(\"Flat Spectrum\")\n",
    "    ax[2].set_xlabel(\"Frequency Bin\")\n",
    "    ax[2].set_ylabel(\"Power (log scale)\")\n",
    "\n",
    "\n",
    "    ax[3].clear()\n",
    "    x_values = segments_df['freq'][0][peak_fit_range[0]:peak_fit_range[1]+1]\n",
    "    ax[3].plot(segments_df['freq'][0][peak_fit_range[0]:peak_fit_range[1]+1], segments_df.iloc[index]['flat_specs'][0])\n",
    "\n",
    "    for i in range(len(segments_df.iloc[index]['peak_gauss'])):\n",
    "        freq_values = segments_df['freq'][i][peak_fit_range[0]:peak_fit_range[1]+1]\n",
    "        ax[3].plot(freq_values, segments_df.iloc[index]['flat_specs'][i+1])\n",
    "        ax[3].plot(freq_values, segments_df.iloc[index]['peak_gauss'][i], linestyle=\":\", color=\"grey\")\n",
    "\n",
    "    # Setting titles and labels\n",
    "    ax[3].set_title(\"Peak Fits\")\n",
    "    ax[3].set_xlabel(\"Frequency Bin\")\n",
    "    ax[3].set_ylabel(\"Power (log scale)\")\n",
    "\n",
    "    # Set x-axis ticks to steps of 1\n",
    "    ax[3].set_xticks(np.arange(min(x_values), max(x_values)+1, 1))\n",
    "\n",
    "    # Adjust layout and redraw\n",
    "    fig.suptitle(f\"Index: {index}, Channel: {ch}, Start Position: {start_pos}, Cue Onset: {cue_onset}\")\n",
    "    fig.tight_layout()\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "# Function to sort the DataFrame based on selected column\n",
    "def sort_segments(order_by):\n",
    "    global segments_df\n",
    "    global sorted_indices\n",
    "    segments_df.sort_values(by=order_by, inplace=True)\n",
    "    segments_df.reset_index(drop=True, inplace=True)\n",
    "    sorted_indices = list(range(len(segments_df)))\n",
    "    current_index[0] = 0\n",
    "    update_plot(current_index[0])\n",
    "    index_input.value = str(current_index[0])\n",
    "\n",
    "# Initial plot\n",
    "update_plot(current_index[0])\n",
    "\n",
    "# Event handler for key press\n",
    "def on_key(event):\n",
    "    if event.key == 'right':  # Navigate forward\n",
    "        current_index[0] = (current_index[0] + 1) % len(segments_df)\n",
    "    elif event.key == 'left':  # Navigate backward\n",
    "        current_index[0] = (current_index[0] - 1) % len(segments_df)\n",
    "    update_plot(current_index[0])\n",
    "    index_input.value = str(current_index[0])  # Sync text input with current index\n",
    "\n",
    "# Connect key press events\n",
    "fig.canvas.mpl_connect('key_press_event', on_key)\n",
    "\n",
    "# Create a text box for index input\n",
    "index_input = widgets.Text(\n",
    "    value=str(current_index[0]),\n",
    "    description=\"Index:\",\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "# Function to handle text input\n",
    "def on_text_submit(change):\n",
    "    try:\n",
    "        new_index = int(change[\"new\"])\n",
    "        if 0 <= new_index < len(segments_df):\n",
    "            current_index[0] = new_index\n",
    "            update_plot(current_index[0])\n",
    "        else:\n",
    "            index_input.value = str(current_index[0])  # Reset to current index if invalid\n",
    "    except ValueError:\n",
    "        index_input.value = str(current_index[0])  # Reset to current index if invalid\n",
    "\n",
    "# Attach the handler to text input\n",
    "index_input.observe(on_text_submit, names=\"value\")\n",
    "\n",
    "# Dropdown menu for sorting\n",
    "sort_dropdown = widgets.Dropdown(\n",
    "    options=['channel', 'start_position', 'cue_onset'],\n",
    "    description='Sort by:',\n",
    "    style={\"description_width\": \"initial\"}\n",
    ")\n",
    "\n",
    "# Function to handle dropdown selection\n",
    "def on_sort_change(change):\n",
    "    sort_segments(change[\"new\"])\n",
    "\n",
    "# Attach the handler to dropdown\n",
    "sort_dropdown.observe(on_sort_change, names=\"value\")\n",
    "\n",
    "# Display the text input, dropdown, and plot\n",
    "ui = VBox([HBox([index_input, sort_dropdown])])\n",
    "display(ui)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_of_interest = [\"019\", \"023\", \"029\", \"030\", \"043\", \"045\"]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8), sharex=True, sharey=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ch in enumerate(channels_of_interest):\n",
    "    filtered_df = segments_df[segments_df['channel'] == ch]\n",
    "\n",
    "    peak_stds = filtered_df['peak_stds'].apply(pd.Series)\n",
    "    peaks = filtered_df['peaks'].apply(pd.Series)\n",
    "    peak_means = filtered_df['peak_means'].apply(pd.Series)  # Split into separate columns\n",
    "\n",
    "    for col in peak_means.columns:\n",
    "        normalised_peaks = (peaks[col])/peak_stds[col]\n",
    "        axes[i].hist(normalised_peaks, bins=50, alpha=0.5, label=f'Peak {col+1}')\n",
    "    \n",
    "    axes[i].set_title(f'Channel {ch}')\n",
    "    axes[i].legend()\n",
    "\n",
    "fig.suptitle(f\"Distribution of Normalised Peaks Magnitude {day}\")\n",
    "fig.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define theta range\n",
    "theta_range = (2, 12)\n",
    "\n",
    "# Data structures to store ANOVA and Post-Hoc results\n",
    "anova_results = []\n",
    "posthoc_results = []\n",
    "\n",
    "for ch in channels_of_interest:\n",
    "    # Plot setup for each channel\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, start_position in enumerate(np.sort(segments_df['start_position'].unique())):\n",
    "        ax = axes[i]\n",
    "        theta_power_by_cue = {}  # Store theta power grouped by cue onset\n",
    "        all_theta_powers = []\n",
    "        all_cue_labels = []\n",
    "\n",
    "        for j, cue_onset in enumerate(np.sort(segments_df['cue_onset'].unique())):\n",
    "            # Filter DataFrame for current start position, channel, and cue onset\n",
    "            filtered_df = segments_df.loc[\n",
    "                (segments_df['start_position'] == start_position) &\n",
    "                (segments_df['channel'] == ch) &\n",
    "                (segments_df['cue_onset'] == cue_onset)\n",
    "            ]\n",
    "\n",
    "            # Ensure there is PSD data to process\n",
    "            if filtered_df.empty:\n",
    "                continue\n",
    "\n",
    "            # Extract PSD and frequency data\n",
    "            psd_list = filtered_df['psd'].tolist()\n",
    "            freq_list = filtered_df['freq'].iloc[0][:150]  # Assuming freq is consistent\n",
    "            psd_array = np.array(psd_list)\n",
    "\n",
    "            # Get indexes for the theta band\n",
    "            theta_indices = (freq_list >= theta_range[0]) & (freq_list <= theta_range[1])\n",
    "            theta_psd = psd_array[:, theta_indices]\n",
    "\n",
    "            # Sum theta power within the theta band for each trial\n",
    "            mean_psd = np.sum(theta_psd, axis=1)\n",
    "            mean_theta_power = np.mean(mean_psd)  # Mean across all trials\n",
    "            sem_theta_power = sem(mean_psd)  # SEM across all trials\n",
    "\n",
    "            # Store theta power data for ANOVA\n",
    "            theta_power_by_cue[cue_onset] = mean_psd\n",
    "            all_theta_powers.extend(mean_psd)\n",
    "            all_cue_labels.extend([cue_onset] * len(mean_psd))\n",
    "\n",
    "            # Plot mean and SEM\n",
    "            ax.bar(j + 1, mean_theta_power, yerr=sem_theta_power, label=f'Cue {cue_onset}', alpha=0.7)\n",
    "\n",
    "        # Customize subplot\n",
    "        ax.set_title(f'Start: Poster {start_position % 10}')\n",
    "        ax.set_xlabel('Cue Poster')\n",
    "        ax.set_ylabel('Theta Power (μV²)')\n",
    "        ax.set_xticks(np.arange(1, len(np.unique(segments_df['cue_onset'])) + 1, 1))\n",
    "        ax.legend(loc=\"lower right\", fontsize='small')\n",
    "\n",
    "        # Perform ANOVA if there are at least two cue groups\n",
    "        if len(theta_power_by_cue) > 1:\n",
    "            f_stat, p_value = f_oneway(*theta_power_by_cue.values())\n",
    "            anova_results.append({\n",
    "                'channel': ch,\n",
    "                'start_position': start_position,\n",
    "                'f_stat': f_stat,\n",
    "                'p_value': p_value\n",
    "            })\n",
    "\n",
    "            # Perform post-hoc Tukey HSD if ANOVA is significant\n",
    "            if p_value < 0.05:\n",
    "                tukey_result = pairwise_tukeyhsd(endog=all_theta_powers,\n",
    "                                                 groups=all_cue_labels,\n",
    "                                                 alpha=0.05)\n",
    "\n",
    "                # Store post-hoc results\n",
    "                for res in tukey_result.summary().data[1:]:  # Skip header\n",
    "                    posthoc_results.append({\n",
    "                        'channel': ch,\n",
    "                        'start_position': start_position,\n",
    "                        'group1': res[0],\n",
    "                        'group2': res[1],\n",
    "                        'mean_diff': res[2],\n",
    "                        'p_adj': res[3],\n",
    "                        'lower': res[4],\n",
    "                        'upper': res[5],\n",
    "                        'reject': res[6]\n",
    "                    })\n",
    "\n",
    "    # Adjust layout and add main title\n",
    "    plt.suptitle(f'Theta Power Across Cue Posters for Channel {ch}')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Convert ANOVA results to DataFrame\n",
    "anova_results_df = pd.DataFrame(anova_results)\n",
    "posthoc_results_df = pd.DataFrame(posthoc_results)\n",
    "\n",
    "# Save results to CSV files\n",
    "anova_results_df.to_csv(\"anova_results_theta_power.csv\", index=False)\n",
    "posthoc_results_df.to_csv(\"posthoc_results_theta_power.csv\", index=False)\n",
    "\n",
    "print(\"ANOVA results saved to anova_results_theta_power.csv\")\n",
    "print(\"Post-hoc Tukey results saved to posthoc_results_theta_power.csv\")\n",
    "\n",
    "# Display significant post-hoc results\n",
    "significant_posthoc = posthoc_results_df[posthoc_results_df['reject'] == True]\n",
    "print(\"\\nSignificant Post-Hoc Results: \\n\", significant_posthoc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define theta range\n",
    "theta_range = (2, 12)\n",
    "\n",
    "# Define pillar groups and corresponding colors\n",
    "pillar_colors = [[11, 16], [12], [13], [14, 15]]\n",
    "pillar_color_map = {\n",
    "    0: 'blue',    # Pillar 1: Cue Posters 11 & 16\n",
    "    1: 'yellow',  # Pillar 2: Cue Poster 12\n",
    "    2: 'green',   # Pillar 3: Cue Poster 13\n",
    "    3: 'red'      # Pillar 4: Cue Posters 14 & 15\n",
    "}\n",
    "\n",
    "anova_results = []\n",
    "posthoc_results = []\n",
    "\n",
    "for ch in channels_of_interest:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(9, 6), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, start_position in enumerate(np.sort(segments_df['start_position'].unique())):\n",
    "        ax = axes[i]\n",
    "        theta_power_by_pillar = {}  # Store theta power for each pillar\n",
    "\n",
    "        for pillar_idx, pillar_group in enumerate(pillar_colors):\n",
    "            combined_theta_powers = []\n",
    "\n",
    "            for cue_onset in pillar_group:\n",
    "                filtered_df = segments_df.loc[\n",
    "                    (segments_df['start_position'] == start_position) &\n",
    "                    (segments_df['channel'] == ch) &\n",
    "                    (segments_df['cue_onset'] == cue_onset)\n",
    "                ]\n",
    "\n",
    "                if filtered_df.empty:\n",
    "                    continue\n",
    "\n",
    "                # Extract PSD and frequency data\n",
    "                psd_list = filtered_df['psd'].tolist()\n",
    "                freq_list = filtered_df['freq'].iloc[0][:150]  # Assuming freq is consistent\n",
    "                psd_array = np.array(psd_list)\n",
    "\n",
    "                # Get indexes for the theta band\n",
    "                theta_indices = (freq_list >= theta_range[0]) & (freq_list <= theta_range[1])\n",
    "                theta_psd = psd_array[:, theta_indices]\n",
    "\n",
    "                # Sum theta power within the theta band for each trial\n",
    "                mean_psd = np.sum(theta_psd, axis=1)\n",
    "                combined_theta_powers.extend(mean_psd)\n",
    "\n",
    "            if combined_theta_powers:\n",
    "                mean_theta_power = np.mean(combined_theta_powers)\n",
    "                sem_theta_power = sem(combined_theta_powers)\n",
    "\n",
    "                # Store data for ANOVA\n",
    "                theta_power_by_pillar[f'Pillar {pillar_idx+1}'] = combined_theta_powers\n",
    "\n",
    "                # Plot mean and SEM\n",
    "                ax.bar(pillar_idx + 1, mean_theta_power, yerr=sem_theta_power,\n",
    "                       color=pillar_color_map[pillar_idx], alpha=0.7)\n",
    "\n",
    "        # Run ANOVA if we have theta power data from at least two pillars\n",
    "        if len(theta_power_by_pillar) > 1:\n",
    "            f_stat, p_value = f_oneway(*theta_power_by_pillar.values())\n",
    "            anova_results.append({\n",
    "                'channel': ch,\n",
    "                'start_position': start_position,\n",
    "                'f_stat': f_stat,\n",
    "                'p_value': p_value\n",
    "            })\n",
    "\n",
    "            # Perform Tukey HSD post-hoc if ANOVA is significant\n",
    "            if p_value < 0.05:\n",
    "                all_theta_powers = []\n",
    "                all_pillar_labels = []\n",
    "\n",
    "                for pillar, values in theta_power_by_pillar.items():\n",
    "                    all_theta_powers.extend(values)\n",
    "                    all_pillar_labels.extend([pillar] * len(values))\n",
    "\n",
    "                tukey_result = pairwise_tukeyhsd(endog=all_theta_powers,\n",
    "                                                 groups=all_pillar_labels,\n",
    "                                                 alpha=0.05)\n",
    "\n",
    "                # Store post-hoc results\n",
    "                for res in tukey_result.summary().data[1:]:  # Skip header\n",
    "                    posthoc_results.append({\n",
    "                        'channel': ch,\n",
    "                        'start_position': start_position,\n",
    "                        'group1': res[0],\n",
    "                        'group2': res[1],\n",
    "                        'mean_diff': res[2],\n",
    "                        'p_adj': res[3],\n",
    "                        'lower': res[4],\n",
    "                        'upper': res[5],\n",
    "                        'reject': res[6]\n",
    "                    })\n",
    "\n",
    "        # Customize subplot\n",
    "        ax.set_title(f'Start: Poster {start_position % 10}')\n",
    "        ax.set_xlabel('Cue Pillar')\n",
    "        ax.set_ylabel('Theta Power (μV²)')\n",
    "        ax.set_xticks([1, 2, 3, 4])\n",
    "        ax.set_xticklabels([f'Pillar {idx+1}' for idx in range(len(pillar_colors))], rotation=45)\n",
    "\n",
    "    # Create a custom legend\n",
    "    custom_legend = [\n",
    "        plt.Line2D([0], [0], color='blue', lw=4, label='Pillar 1: Cue Posters 11 & 16'),\n",
    "        plt.Line2D([0], [0], color='yellow', lw=4, label='Pillar 2: Cue Poster 12'),\n",
    "        plt.Line2D([0], [0], color='green', lw=4, label='Pillar 3: Cue Poster 13'),\n",
    "        plt.Line2D([0], [0], color='red', lw=4, label='Pillar 4: Cue Posters 14 & 15')\n",
    "    ]\n",
    "    fig.legend(handles=custom_legend, loc='upper right', fontsize='medium')\n",
    "\n",
    "    plt.suptitle(f'Combined Theta Power by Pillar for Channel {ch}')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Save ANOVA and post-hoc results\n",
    "anova_results_df = pd.DataFrame(anova_results)\n",
    "posthoc_results_df = pd.DataFrame(posthoc_results)\n",
    "\n",
    "anova_results_df.to_csv(\"anova_results_theta_power_by_pillar.csv\", index=False)\n",
    "posthoc_results_df.to_csv(\"posthoc_tukey_results_theta_power_by_pillar.csv\", index=False)\n",
    "\n",
    "print(\"ANOVA results saved to anova_results_theta_power_by_pillar.csv\")\n",
    "print(\"Post-hoc Tukey results saved to posthoc_tukey_results_theta_power_by_pillar.csv\")\n",
    "\n",
    "# Display significant post-hoc results\n",
    "significant_posthoc = posthoc_results_df[posthoc_results_df['reject'] == True]\n",
    "print(\"\\nSignificant Post-Hoc Results:\\n\", significant_posthoc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define theta range\n",
    "theta_range = (2, 12)\n",
    "\n",
    "# Data structures to store ANOVA and Post-Hoc results by starting position\n",
    "anova_start_pos_results = []\n",
    "posthoc_start_pos_results = []\n",
    "\n",
    "for ch in channels_of_interest:\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "    theta_power_by_start_pos = {}  # Store theta power for each starting position\n",
    "\n",
    "    for start_position in np.sort(segments_df['start_position'].unique()):\n",
    "        combined_theta_powers = []\n",
    "\n",
    "        # Aggregate theta power for all cue onsets from this starting position\n",
    "        filtered_df = segments_df.loc[\n",
    "            (segments_df['start_position'] == start_position) &\n",
    "            (segments_df['channel'] == ch)\n",
    "        ]\n",
    "\n",
    "        if filtered_df.empty:\n",
    "            continue\n",
    "\n",
    "        # Extract PSD and frequency data\n",
    "        psd_list = filtered_df['psd'].tolist()\n",
    "        freq_list = filtered_df['freq'].iloc[0][:150]  # Assuming freq is consistent\n",
    "        psd_array = np.array(psd_list)\n",
    "\n",
    "        # Get indexes for the theta band\n",
    "        theta_indices = (freq_list >= theta_range[0]) & (freq_list <= theta_range[1])\n",
    "        theta_psd = psd_array[:, theta_indices]\n",
    "\n",
    "        # Sum theta power within the theta band for each trial\n",
    "        mean_psd = np.sum(theta_psd, axis=1)\n",
    "        combined_theta_powers.extend(mean_psd)\n",
    "\n",
    "        if combined_theta_powers:\n",
    "            mean_theta_power = np.mean(combined_theta_powers)\n",
    "            sem_theta_power = sem(combined_theta_powers)\n",
    "\n",
    "            # Store data for ANOVA\n",
    "            theta_power_by_start_pos[f'Start {start_position}'] = combined_theta_powers\n",
    "\n",
    "            # Plot mean and SEM\n",
    "            ax.bar(start_position, mean_theta_power, yerr=sem_theta_power, alpha=0.7, label=f'Start {start_position}')\n",
    "\n",
    "    # Run ANOVA if we have theta power data from at least two starting positions\n",
    "    if len(theta_power_by_start_pos) > 1:\n",
    "        f_stat, p_value = f_oneway(*theta_power_by_start_pos.values())\n",
    "        anova_start_pos_results.append({\n",
    "            'channel': ch,\n",
    "            'f_stat': f_stat,\n",
    "            'p_value': p_value\n",
    "        })\n",
    "\n",
    "        # Perform Tukey HSD post-hoc if ANOVA is significant\n",
    "        if p_value < 0.05:\n",
    "            all_theta_powers = []\n",
    "            all_start_pos_labels = []\n",
    "\n",
    "            for start_pos, values in theta_power_by_start_pos.items():\n",
    "                all_theta_powers.extend(values)\n",
    "                all_start_pos_labels.extend([start_pos] * len(values))\n",
    "\n",
    "            tukey_result = pairwise_tukeyhsd(endog=all_theta_powers,\n",
    "                                             groups=all_start_pos_labels,\n",
    "                                             alpha=0.05)\n",
    "\n",
    "            # Store post-hoc results\n",
    "            for res in tukey_result.summary().data[1:]:  # Skip header\n",
    "                posthoc_start_pos_results.append({\n",
    "                    'channel': ch,\n",
    "                    'group1': res[0],\n",
    "                    'group2': res[1],\n",
    "                    'mean_diff': res[2],\n",
    "                    'p_adj': res[3],\n",
    "                    'lower': res[4],\n",
    "                    'upper': res[5],\n",
    "                    'reject': res[6]\n",
    "                })\n",
    "\n",
    "    # Customize plot\n",
    "    ax.set_title(f'Theta Power by Starting Position for Ch {ch}')\n",
    "    ax.set_xlabel('Starting Position')\n",
    "    ax.set_ylabel('Theta Power (μV²)')\n",
    "    ax.legend(loc='lower right', fontsize='small')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Save ANOVA and post-hoc results for starting positions\n",
    "anova_start_pos_df = pd.DataFrame(anova_start_pos_results)\n",
    "posthoc_start_pos_df = pd.DataFrame(posthoc_start_pos_results)\n",
    "\n",
    "anova_start_pos_df.to_csv(\"anova_results_theta_power_by_starting_position.csv\", index=False)\n",
    "posthoc_start_pos_df.to_csv(\"posthoc_tukey_results_theta_power_by_starting_position.csv\", index=False)\n",
    "\n",
    "print(\"ANOVA results saved to anova_results_theta_power_by_starting_position.csv\")\n",
    "print(\"Post-hoc Tukey results saved to posthoc_tukey_results_theta_power_by_starting_position.csv\")\n",
    "\n",
    "# Display significant post-hoc results\n",
    "significant_posthoc_start_pos = posthoc_start_pos_df[posthoc_start_pos_df['reject'] == True]\n",
    "print(\"\\nSignificant Post-Hoc Results (Starting Positions):\\n\", significant_posthoc_start_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_left = {\n",
    "   31: [12,],\n",
    "   32: [11,],\n",
    "   33: [11,],\n",
    "   34: [13,],\n",
    "   35: [11,12,16],\n",
    "   36: [13,14,15]\n",
    "   }\n",
    "go_right = {\n",
    "   31: [13,14,15,16],\n",
    "   32: [13,15,14,16],\n",
    "   33: [12,14,15,16],\n",
    "   34: [11,12,15,16],\n",
    "   35: [13,14],\n",
    "   36: [11,12]\n",
    "   }\n",
    "\n",
    "\n",
    "north = { \n",
    "    31: [12,14,15,16],\n",
    "    32: [],\n",
    "    33: [14,15],\n",
    "    34: [],\n",
    "    35: [14,],\n",
    "    36: [12,14]\n",
    "    }\n",
    "\n",
    "south = { \n",
    "    31: [],\n",
    "    32: [11,16],\n",
    "    33: [],\n",
    "    34: [11,13,15,16],\n",
    "    35: [11,13],\n",
    "    36: [11,]\n",
    "    }\n",
    "\n",
    "east = { \n",
    "    31: [13,],\n",
    "    32: [13,14,15],\n",
    "    33: [],\n",
    "    34: [],\n",
    "    35: [],\n",
    "    36: [13,15]\n",
    "    }\n",
    "\n",
    "west = { \n",
    "    31: [],\n",
    "    32: [],\n",
    "    33: [11,12,16],\n",
    "    34: [12,],\n",
    "    35: [12,16],\n",
    "    36: []\n",
    "    }\n",
    "\n",
    "front = { \n",
    "    31: [12,14,15,16],\n",
    "    32: [13,14,15],\n",
    "    33: [11,12,16],\n",
    "    34: [11,13,15,16],\n",
    "    35: [14,],\n",
    "    36: [11,]\n",
    "    }\n",
    "\n",
    "behind = { \n",
    "    31: [],\n",
    "    32: [],\n",
    "    33: [],\n",
    "    34: [],\n",
    "    35: [11,13,16],\n",
    "    36: [12,14,15]\n",
    "    }\n",
    "\n",
    "left = { \n",
    "    31: [12,],\n",
    "    32: [14,],\n",
    "    33: [11,],\n",
    "    34: [13,],\n",
    "    35: [11,12,16],\n",
    "    36: [13,14,15]\n",
    "    }\n",
    "\n",
    "right = { \n",
    "    31: [13,14,15],\n",
    "    32: [11,13,16],\n",
    "    33: [12,14,15,16],\n",
    "    34: [12,16],\n",
    "    35: [13,],\n",
    "    36: [12,]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, sem\n",
    "\n",
    "# Define theta range\n",
    "theta_range = (2, 12)\n",
    "\n",
    "# Data structure to store statistical test results\n",
    "ttest_results = []\n",
    "\n",
    "# Iterate through channels of interest\n",
    "for ch in channels_of_interest:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(5, 5), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, start_position in enumerate(np.sort(segments_df['start_position'].unique())):\n",
    "        ax = axes[i]\n",
    "\n",
    "        left_theta_powers = []\n",
    "        right_theta_powers = []\n",
    "\n",
    "        for j, cue_onset in enumerate(np.sort(segments_df['cue_onset'].unique())):\n",
    "            prev_reward = start_position  # Since start_position corresponds to the previous reward\n",
    "\n",
    "            # Determine if this cue_onset belongs to left or right movement\n",
    "            if prev_reward in go_left and cue_onset in go_left[prev_reward]:\n",
    "                move_direction = \"left\"\n",
    "            elif prev_reward in go_right and cue_onset in go_right[prev_reward]:\n",
    "                move_direction = \"right\"\n",
    "            else:\n",
    "                continue  # Ignore if it's neither left nor right\n",
    "\n",
    "            # Filter DataFrame for current start position, channel, and cue onset\n",
    "            filtered_df = segments_df.loc[\n",
    "                (segments_df['start_position'] == start_position) &\n",
    "                (segments_df['channel'] == ch) &\n",
    "                (segments_df['cue_onset'] == cue_onset)\n",
    "            ]\n",
    "\n",
    "            if filtered_df.empty:\n",
    "                continue\n",
    "\n",
    "            # Extract PSD and frequency data\n",
    "            psd_list = filtered_df['psd'].tolist()\n",
    "            freq_list = filtered_df['freq'].iloc[0][:150]  # Assuming freq is consistent\n",
    "            psd_array = np.array(psd_list)\n",
    "\n",
    "            # Get indexes for the theta band\n",
    "            theta_indices = (freq_list >= theta_range[0]) & (freq_list <= theta_range[1])\n",
    "            theta_psd = psd_array[:, theta_indices]\n",
    "\n",
    "            # Sum theta power within the theta band for each trial\n",
    "            mean_psd = np.sum(theta_psd, axis=1)\n",
    "\n",
    "            # Store in corresponding movement direction\n",
    "            if move_direction == \"left\":\n",
    "                left_theta_powers.extend(mean_psd)\n",
    "            else:\n",
    "                right_theta_powers.extend(mean_psd)\n",
    "\n",
    "        # Compute mean and SEM\n",
    "        mean_left = np.mean(left_theta_powers) if left_theta_powers else np.nan\n",
    "        sem_left = sem(left_theta_powers) if left_theta_powers else np.nan\n",
    "        mean_right = np.mean(right_theta_powers) if right_theta_powers else np.nan\n",
    "        sem_right = sem(right_theta_powers) if right_theta_powers else np.nan\n",
    "\n",
    "        # Plot bar graph for left vs right movements\n",
    "        ax.bar(1, mean_left, yerr=sem_left, label=\"Left\", alpha=0.7, color=\"blue\")\n",
    "        ax.bar(2, mean_right, yerr=sem_right, label=\"Right\", alpha=0.7, color=\"red\")\n",
    "\n",
    "        ax.set_title(f'Start: Poster {start_position % 10}')\n",
    "        ax.set_xticks([1, 2])\n",
    "        ax.set_xticklabels([\"Left\", \"Right\"])\n",
    "        ax.set_ylabel('Theta Power (μV²)')\n",
    "        ax.legend(loc='lower right')\n",
    "\n",
    "        # Perform t-test if both groups have data\n",
    "        if len(left_theta_powers) > 1 and len(right_theta_powers) > 1:\n",
    "            t_stat, p_ttest = ttest_ind(left_theta_powers, right_theta_powers, equal_var=False)  # Welch’s t-test\n",
    "            \n",
    "            # Store results\n",
    "            ttest_results.append({\n",
    "                'channel': ch,\n",
    "                'start_position': start_position,\n",
    "                't_stat': t_stat,\n",
    "                'p_ttest': p_ttest\n",
    "            })\n",
    "\n",
    "    plt.suptitle(f'Theta Power for Left vs Right Movements - Channel {ch}')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Convert test results to DataFrame\n",
    "ttest_results_df = pd.DataFrame(ttest_results)\n",
    "\n",
    "# Save results to CSV files\n",
    "ttest_results_df.to_csv(\"ttest_results_theta_power_left_right.csv\", index=False)\n",
    "\n",
    "print(\"T-test results saved to ttest_results_theta_power_left_right.csv\")\n",
    "\n",
    "# Display significant results\n",
    "significant_results = ttest_results_df[ttest_results_df['p_ttest'] < 0.05]\n",
    "print(\"\\nSignificant Differences in Theta Power (T-test): \\n\", significant_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind, sem\n",
    "\n",
    "# Define theta range\n",
    "theta_range = (2, 12)\n",
    "\n",
    "# Data structure to store statistical test results\n",
    "ttest_results = []\n",
    "\n",
    "# Iterate through channels of interest\n",
    "for ch in channels_of_interest:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(5.5, 5), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, start_position in enumerate(np.sort(segments_df['start_position'].unique())):\n",
    "        ax = axes[i]\n",
    "\n",
    "        left_theta_powers = []\n",
    "        right_theta_powers = []\n",
    "\n",
    "        for j, cue_onset in enumerate(np.sort(segments_df['cue_onset'].unique())):\n",
    "            prev_reward = start_position  # Since start_position corresponds to the previous reward\n",
    "\n",
    "            # Determine if this cue_onset belongs to left or right movement\n",
    "            if prev_reward in left and cue_onset in left[prev_reward]:\n",
    "                move_direction = \"left\"\n",
    "            elif prev_reward in right and cue_onset in right[prev_reward]:\n",
    "                move_direction = \"right\"\n",
    "            else:\n",
    "                continue  # Ignore if it's neither left nor right\n",
    "\n",
    "            # Filter DataFrame for current start position, channel, and cue onset\n",
    "            filtered_df = segments_df.loc[\n",
    "                (segments_df['start_position'] == start_position) &\n",
    "                (segments_df['channel'] == ch) &\n",
    "                (segments_df['cue_onset'] == cue_onset)\n",
    "            ]\n",
    "\n",
    "            if filtered_df.empty:\n",
    "                continue\n",
    "\n",
    "            # Extract PSD and frequency data\n",
    "            psd_list = filtered_df['psd'].tolist()\n",
    "            freq_list = filtered_df['freq'].iloc[0][:150]  # Assuming freq is consistent\n",
    "            psd_array = np.array(psd_list)\n",
    "\n",
    "            # Get indexes for the theta band\n",
    "            theta_indices = (freq_list >= theta_range[0]) & (freq_list <= theta_range[1])\n",
    "            theta_psd = psd_array[:, theta_indices]\n",
    "\n",
    "            # Sum theta power within the theta band for each trial\n",
    "            mean_psd = np.sum(theta_psd, axis=1)\n",
    "\n",
    "            # Store in corresponding movement direction\n",
    "            if move_direction == \"left\":\n",
    "                left_theta_powers.extend(mean_psd)\n",
    "            else:\n",
    "                right_theta_powers.extend(mean_psd)\n",
    "\n",
    "        # Compute mean and SEM\n",
    "        mean_left = np.mean(left_theta_powers) if left_theta_powers else np.nan\n",
    "        sem_left = sem(left_theta_powers) if left_theta_powers else np.nan\n",
    "        mean_right = np.mean(right_theta_powers) if right_theta_powers else np.nan\n",
    "        sem_right = sem(right_theta_powers) if right_theta_powers else np.nan\n",
    "\n",
    "        # Plot bar graph for left vs right movements\n",
    "        ax.bar(1, mean_left, yerr=sem_left, label=\"Left\", alpha=0.7, color=\"blue\")\n",
    "        ax.bar(2, mean_right, yerr=sem_right, label=\"Right\", alpha=0.7, color=\"red\")\n",
    "\n",
    "        ax.set_title(f'Start: Poster {start_position % 10}')\n",
    "        ax.set_xticks([1, 2])\n",
    "        ax.set_xticklabels([\"Left\", \"Right\"])\n",
    "        ax.set_ylabel('Theta Power (μV²)')\n",
    "        ax.legend(loc='lower right')\n",
    "\n",
    "        # Perform t-test if both groups have data\n",
    "        if len(left_theta_powers) > 1 and len(right_theta_powers) > 1:\n",
    "            t_stat, p_ttest = ttest_ind(left_theta_powers, right_theta_powers, equal_var=False)  # Welch’s t-test\n",
    "            \n",
    "            # Store results\n",
    "            ttest_results.append({\n",
    "                'channel': ch,\n",
    "                'start_position': start_position,\n",
    "                't_stat': t_stat,\n",
    "                'p_ttest': p_ttest\n",
    "            })\n",
    "\n",
    "    plt.suptitle(f'Theta Power for L vs R Relative Poster Position - Ch{ch}')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Convert test results to DataFrame\n",
    "ttest_results_df = pd.DataFrame(ttest_results)\n",
    "\n",
    "# Save results to CSV files\n",
    "ttest_results_df.to_csv(\"ttest_results_theta_power_left_right_relative_position.csv\", index=False)\n",
    "\n",
    "print(\"T-test results saved to ttest_results_theta_power_left_right_relative_position.csv\")\n",
    "\n",
    "# Display significant results\n",
    "significant_results = ttest_results_df[ttest_results_df['p_ttest'] < 0.05]\n",
    "print(\"\\nSignificant Differences in Theta Power (T-test): \\n\", significant_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define theta range\n",
    "theta_range = (2, 12)\n",
    "\n",
    "# Data structure to store statistical test results\n",
    "ttest_results = []\n",
    "\n",
    "# Iterate through channels of interest\n",
    "for ch in channels_of_interest:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(5.5, 5), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, start_position in enumerate(np.sort(segments_df['start_position'].unique())):\n",
    "        ax = axes[i]\n",
    "\n",
    "        front_theta_powers = []\n",
    "        behind_theta_powers = []\n",
    "\n",
    "        for j, cue_onset in enumerate(np.sort(segments_df['cue_onset'].unique())):\n",
    "            prev_reward = start_position  # Since start_position corresponds to the previous reward\n",
    "\n",
    "            # Determine if this cue_onset belongs to front or behind\n",
    "            if prev_reward in front and cue_onset in front[prev_reward]:\n",
    "                move_direction = \"front\"\n",
    "            elif prev_reward in behind and cue_onset in behind[prev_reward]:\n",
    "                move_direction = \"behind\"\n",
    "            else:\n",
    "                continue  # Ignore if it's neither front nor behind\n",
    "\n",
    "            # Filter DataFrame for current start position, channel, and cue onset\n",
    "            filtered_df = segments_df.loc[\n",
    "                (segments_df['start_position'] == start_position) &\n",
    "                (segments_df['channel'] == ch) &\n",
    "                (segments_df['cue_onset'] == cue_onset)\n",
    "            ]\n",
    "\n",
    "            if filtered_df.empty:\n",
    "                continue\n",
    "\n",
    "            # Extract PSD and frequency data\n",
    "            psd_list = filtered_df['psd'].tolist()\n",
    "            freq_list = filtered_df['freq'].iloc[0][:150]  # Assuming freq is consistent\n",
    "            psd_array = np.array(psd_list)\n",
    "\n",
    "            # Get indexes for the theta band\n",
    "            theta_indices = (freq_list >= theta_range[0]) & (freq_list <= theta_range[1])\n",
    "            theta_psd = psd_array[:, theta_indices]\n",
    "\n",
    "            # Sum theta power within the theta band for each trial\n",
    "            mean_psd = np.sum(theta_psd, axis=1)\n",
    "\n",
    "            # Store in corresponding movement direction\n",
    "            if move_direction == \"front\":\n",
    "                front_theta_powers.extend(mean_psd)\n",
    "            else:\n",
    "                behind_theta_powers.extend(mean_psd)\n",
    "\n",
    "        # Compute mean and SEM\n",
    "        mean_front = np.mean(front_theta_powers) if front_theta_powers else np.nan\n",
    "        sem_front = sem(front_theta_powers) if front_theta_powers else np.nan\n",
    "        mean_behind = np.mean(behind_theta_powers) if behind_theta_powers else np.nan\n",
    "        sem_behind = sem(behind_theta_powers) if behind_theta_powers else np.nan\n",
    "\n",
    "        # Plot bar graph for front vs behind\n",
    "        ax.bar(1, mean_front, yerr=sem_front, label=\"Front\", alpha=0.7, color=\"blue\")\n",
    "        ax.bar(2, mean_behind, yerr=sem_behind, label=\"Behind\", alpha=0.7, color=\"red\")\n",
    "\n",
    "        ax.set_title(f'Start: Poster {start_position % 10}')\n",
    "        ax.set_xticks([1, 2])\n",
    "        ax.set_xticklabels([\"Front\", \"Behind\"])\n",
    "        ax.set_ylabel('Theta Power (μV²)')\n",
    "        ax.legend(loc='lower right')\n",
    "\n",
    "        # Perform t-test if both groups have data\n",
    "        if len(front_theta_powers) > 1 and len(behind_theta_powers) > 1:\n",
    "            t_stat, p_ttest = ttest_ind(front_theta_powers, behind_theta_powers, equal_var=False)  # Welch’s t-test\n",
    "            \n",
    "            # Store results\n",
    "            ttest_results.append({\n",
    "                'channel': ch,\n",
    "                'start_position': start_position,\n",
    "                't_stat': t_stat,\n",
    "                'p_ttest': p_ttest\n",
    "            })\n",
    "\n",
    "    plt.suptitle(f'Theta Power for Front vs Behind Relative Poster Position - Ch{ch}')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Convert test results to DataFrame\n",
    "ttest_results_df = pd.DataFrame(ttest_results)\n",
    "\n",
    "# Save results to CSV files\n",
    "ttest_results_df.to_csv(\"ttest_results_theta_power_front_behind_relative_position.csv\", index=False)\n",
    "\n",
    "print(\"T-test results saved to ttest_results_theta_power_front_behind_relative_position.csv\")\n",
    "\n",
    "# Display significant results\n",
    "significant_results = ttest_results_df[ttest_results_df['p_ttest'] < 0.05]\n",
    "print(\"\\nSignificant Differences in Theta Power (T-test): \\n\", significant_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define theta range\n",
    "theta_range = (2, 12)\n",
    "\n",
    "# Data structure to store ANOVA and Post-Hoc test results\n",
    "anova_results = []\n",
    "posthoc_results = []\n",
    "\n",
    "# Iterate through channels of interest\n",
    "for ch in channels_of_interest:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(8, 5), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, start_position in enumerate(np.sort(segments_df['start_position'].unique())):\n",
    "        ax = axes[i]\n",
    "\n",
    "        theta_power_by_direction = {'North': [], 'South': [], 'East': [], 'West': []}\n",
    "        all_theta_powers = []\n",
    "        all_direction_labels = []\n",
    "\n",
    "        for j, cue_onset in enumerate(np.sort(segments_df['cue_onset'].unique())):\n",
    "            prev_reward = start_position  # Since start_position corresponds to the previous reward\n",
    "\n",
    "            # Determine movement direction\n",
    "            if prev_reward in north and cue_onset in north[prev_reward]:\n",
    "                move_direction = \"North\"\n",
    "            elif prev_reward in south and cue_onset in south[prev_reward]:\n",
    "                move_direction = \"South\"\n",
    "            elif prev_reward in east and cue_onset in east[prev_reward]:\n",
    "                move_direction = \"East\"\n",
    "            elif prev_reward in west and cue_onset in west[prev_reward]:\n",
    "                move_direction = \"West\"\n",
    "            else:\n",
    "                continue  # Ignore if it's not in any direction\n",
    "\n",
    "            # Filter DataFrame for current start position, channel, and cue onset\n",
    "            filtered_df = segments_df.loc[\n",
    "                (segments_df['start_position'] == start_position) &\n",
    "                (segments_df['channel'] == ch) &\n",
    "                (segments_df['cue_onset'] == cue_onset)\n",
    "            ]\n",
    "\n",
    "            if filtered_df.empty:\n",
    "                continue\n",
    "\n",
    "            # Extract PSD and frequency data\n",
    "            psd_list = filtered_df['psd'].tolist()\n",
    "            freq_list = filtered_df['freq'].iloc[0][:150]  # Assuming freq is consistent\n",
    "            psd_array = np.array(psd_list)\n",
    "\n",
    "            # Get indexes for the theta band\n",
    "            theta_indices = (freq_list >= theta_range[0]) & (freq_list <= theta_range[1])\n",
    "            theta_psd = psd_array[:, theta_indices]\n",
    "\n",
    "            # Sum theta power within the theta band for each trial\n",
    "            mean_psd = np.sum(theta_psd, axis=1)\n",
    "            theta_power_by_direction[move_direction].extend(mean_psd)\n",
    "            all_theta_powers.extend(mean_psd)\n",
    "            all_direction_labels.extend([move_direction] * len(mean_psd))\n",
    "\n",
    "        # Compute mean and SEM for each direction\n",
    "        mean_values = {direction: np.mean(theta_power_by_direction[direction]) if theta_power_by_direction[direction] else np.nan for direction in theta_power_by_direction}\n",
    "        sem_values = {direction: sem(theta_power_by_direction[direction]) if theta_power_by_direction[direction] else np.nan for direction in theta_power_by_direction}\n",
    "\n",
    "        # Plot bar graph for movement directions\n",
    "        directions = list(theta_power_by_direction.keys())\n",
    "        means = [mean_values[dir] for dir in directions]\n",
    "        sems = [sem_values[dir] for dir in directions]\n",
    "\n",
    "        ax.bar(range(len(directions)), means, yerr=sems, tick_label=directions, alpha=0.7)\n",
    "        ax.set_title(f'Start: Poster {start_position % 10}')\n",
    "        ax.set_ylabel('Theta Power (μV²)')\n",
    "\n",
    "        # Perform ANOVA if there are at least two direction groups\n",
    "        if sum(len(v) > 0 for v in theta_power_by_direction.values()) > 1:\n",
    "            f_stat, p_value = f_oneway(*[theta_power_by_direction[dir] for dir in directions if theta_power_by_direction[dir]])\n",
    "            anova_results.append({\n",
    "                'channel': ch,\n",
    "                'start_position': start_position,\n",
    "                'f_stat': f_stat,\n",
    "                'p_value': p_value\n",
    "            })\n",
    "\n",
    "            # Perform Tukey's HSD test if ANOVA is significant\n",
    "            if p_value < 0.05:\n",
    "                tukey_result = pairwise_tukeyhsd(endog=all_theta_powers, groups=all_direction_labels, alpha=0.05)\n",
    "                for res in tukey_result.summary().data[1:]:  # Skip header\n",
    "                    posthoc_results.append({\n",
    "                        'channel': ch,\n",
    "                        'start_position': start_position,\n",
    "                        'group1': res[0],\n",
    "                        'group2': res[1],\n",
    "                        'mean_diff': res[2],\n",
    "                        'p_adj': res[3],\n",
    "                        'lower': res[4],\n",
    "                        'upper': res[5],\n",
    "                        'reject': res[6]\n",
    "                    })\n",
    "\n",
    "    plt.suptitle(f'Theta Power for Movement Directions - Ch{ch}')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Convert test results to DataFrame\n",
    "anova_results_df = pd.DataFrame(anova_results)\n",
    "posthoc_results_df = pd.DataFrame(posthoc_results)\n",
    "\n",
    "# Save results to CSV files\n",
    "anova_results_df.to_csv(\"anova_results_theta_power_directions.csv\", index=False)\n",
    "posthoc_results_df.to_csv(\"posthoc_results_theta_power_directions.csv\", index=False)\n",
    "\n",
    "print(\"ANOVA results saved to anova_results_theta_power_directions.csv\")\n",
    "print(\"Post-hoc Tukey results saved to posthoc_results_theta_power_directions.csv\")\n",
    "\n",
    "# Display significant post-hoc results\n",
    "significant_posthoc = posthoc_results_df[posthoc_results_df['reject'] == True]\n",
    "print(\"\\nSignificant Post-Hoc Results: \\n\", significant_posthoc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define theta frequency range\n",
    "theta_range = (2, 12)\n",
    "\n",
    "# Loop through channels of interest\n",
    "for ch in channels_of_interest:\n",
    "    # Create a grid of subplots (adjust rows/columns and figsize as needed)\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(10, 5), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Loop over each unique start poster position\n",
    "    for i, start_position in enumerate(np.sort(segments_df['start_position'].unique())):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Initialize lists to store theta power for each condition\n",
    "        # Condition 1: Going direction (using go_left and go_right)\n",
    "        going_left = []\n",
    "        going_right = []\n",
    "        # Condition 2: Poster position (using left and right)\n",
    "        poster_left = []\n",
    "        poster_right = []\n",
    "        # Condition 3: Relative front/behind (using front and behind)\n",
    "        front_power = []\n",
    "        behind_power = []\n",
    "        \n",
    "        # Iterate over each unique cue onset\n",
    "        for cue_onset in np.sort(segments_df['cue_onset'].unique()):\n",
    "            prev_reward = start_position  # Here, start_position is used as previous reward\n",
    "            \n",
    "            # Filter data for the current start poster, channel, and cue onset\n",
    "            filtered_df = segments_df.loc[\n",
    "                (segments_df['start_position'] == start_position) &\n",
    "                (segments_df['channel'] == ch) &\n",
    "                (segments_df['cue_onset'] == cue_onset)\n",
    "            ]\n",
    "            if filtered_df.empty:\n",
    "                continue\n",
    "\n",
    "            # Extract PSD and frequency data\n",
    "            psd_list = filtered_df['psd'].tolist()\n",
    "            freq_list = filtered_df['freq'].iloc[0][:150]  # assuming freq is consistent\n",
    "            psd_array = np.array(psd_list)\n",
    "            \n",
    "            # Identify theta indices and sum theta power for each trial\n",
    "            theta_indices = (freq_list >= theta_range[0]) & (freq_list <= theta_range[1])\n",
    "            theta_psd = psd_array[:, theta_indices]\n",
    "            mean_psd = np.sum(theta_psd, axis=1)\n",
    "            \n",
    "            # --- Condition 1: Going Left vs Right ---\n",
    "            if prev_reward in go_left and cue_onset in go_left[prev_reward]:\n",
    "                going_left.extend(mean_psd)\n",
    "            elif prev_reward in go_right and cue_onset in go_right[prev_reward]:\n",
    "                going_right.extend(mean_psd)\n",
    "            \n",
    "            # --- Condition 2: Poster Left vs Right ---\n",
    "            if prev_reward in left and cue_onset in left[prev_reward]:\n",
    "                poster_left.extend(mean_psd)\n",
    "            elif prev_reward in right and cue_onset in right[prev_reward]:\n",
    "                poster_right.extend(mean_psd)\n",
    "            \n",
    "            # --- Condition 3: Front vs Behind ---\n",
    "            if prev_reward in front and cue_onset in front[prev_reward]:\n",
    "                front_power.extend(mean_psd)\n",
    "            elif prev_reward in behind and cue_onset in behind[prev_reward]:\n",
    "                behind_power.extend(mean_psd)\n",
    "        \n",
    "        # Helper function to compute mean and SEM\n",
    "        def compute_stats(data):\n",
    "            if len(data) > 0:\n",
    "                return np.mean(data), sem(data)\n",
    "            else:\n",
    "                return np.nan, np.nan\n",
    "        \n",
    "        # Compute statistics for each condition pair\n",
    "        mean_going_left, sem_going_left = compute_stats(going_left)\n",
    "        mean_going_right, sem_going_right = compute_stats(going_right)\n",
    "        mean_poster_left, sem_poster_left = compute_stats(poster_left)\n",
    "        mean_poster_right, sem_poster_right = compute_stats(poster_right)\n",
    "        mean_front, sem_front = compute_stats(front_power)\n",
    "        mean_behind, sem_behind = compute_stats(behind_power)\n",
    "        \n",
    "        # Prepare the data for grouped bar plotting\n",
    "        groups = ['Going L/R', 'Poster L/R', 'Front/Back']\n",
    "        # Each tuple corresponds to the two conditions within a group\n",
    "        means = [\n",
    "            (mean_going_left, mean_going_right),    # Going: Left vs Right\n",
    "            (mean_poster_left, mean_poster_right),   # Poster: Left vs Right\n",
    "            (mean_front, mean_behind)                # Front: Front vs Behind\n",
    "        ]\n",
    "        errors = [\n",
    "            (sem_going_left, sem_going_right),\n",
    "            (sem_poster_left, sem_poster_right),\n",
    "            (sem_front, sem_behind)\n",
    "        ]\n",
    "        \n",
    "        # Define positions for each group on the x-axis\n",
    "        x = np.arange(len(groups))\n",
    "        width = 0.35  # width for each bar\n",
    "        \n",
    "        # Plot bars for each group with error bars\n",
    "        for idx, group in enumerate(groups):\n",
    "            pos = x[idx]\n",
    "            # For the first condition in each pair (e.g., Left or Front)\n",
    "            ax.bar(pos - width/2, means[idx][0], width, yerr=errors[idx][0],\n",
    "                   color='blue', alpha=0.7, label=f'{group} Left' if idx==0 else \"\")\n",
    "            # For the second condition in each pair (e.g., Right or Behind)\n",
    "            ax.bar(pos + width/2, means[idx][1], width, yerr=errors[idx][1],\n",
    "                   color='red', alpha=0.7, label=f'{group} Right' if idx==0 else \"\")\n",
    "        \n",
    "        ax.set_title(f'Start: Poster {start_position % 10}')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(groups)\n",
    "        ax.set_ylabel('Theta Power (μV²)')\n",
    "    \n",
    "    plt.suptitle(f'Theta Power for Different Conditions - Channel {ch}', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import sem, ttest_ind\n",
    "import pandas as pd\n",
    "\n",
    "# Define theta frequency range\n",
    "theta_range = (2, 12)\n",
    "\n",
    "# Data structure to store t-test results\n",
    "ttest_results = []\n",
    "\n",
    "# Specify the start poster and destination posters to compare\n",
    "start_poster = 31\n",
    "destinations = [15, 16]\n",
    "\n",
    "# Loop through channels of interest\n",
    "for ch in channels_of_interest:\n",
    "    # Initialize lists for theta power corresponding to each destination\n",
    "    power_dest3 = []\n",
    "    power_dest6 = []\n",
    "    \n",
    "    # Iterate over the destination conditions (assuming cue_onset codes for destination)\n",
    "    for dest in destinations:\n",
    "        # Filter trials for the current channel, start poster, and destination cue\n",
    "        filtered_df = segments_df.loc[\n",
    "            (segments_df['start_position'] == start_poster) &\n",
    "            (segments_df['channel'] == ch) &\n",
    "            (segments_df['cue_onset'] == dest)\n",
    "        ]\n",
    "        \n",
    "        if filtered_df.empty:\n",
    "            continue\n",
    "        \n",
    "        # Extract PSD and frequency data (assuming frequencies are consistent across trials)\n",
    "        psd_list = filtered_df['psd'].tolist()\n",
    "        freq_list = filtered_df['freq'].iloc[0][:150]  # adjust as needed\n",
    "        psd_array = np.array(psd_list)\n",
    "        \n",
    "        # Get indices for theta band\n",
    "        theta_indices = (freq_list >= theta_range[0]) & (freq_list <= theta_range[1])\n",
    "        theta_psd = psd_array[:, theta_indices]\n",
    "        \n",
    "        # Sum theta power within the band for each trial\n",
    "        mean_psd = np.sum(theta_psd, axis=1)\n",
    "        \n",
    "        # Store results in the corresponding list\n",
    "        if dest == 15:\n",
    "            power_dest3.extend(mean_psd)\n",
    "        elif dest == 16:\n",
    "            power_dest6.extend(mean_psd)\n",
    "    \n",
    "    # Compute mean and SEM for each condition\n",
    "    mean_dest3 = np.mean(power_dest3) if power_dest3 else np.nan\n",
    "    sem_dest3 = sem(power_dest3) if power_dest3 else np.nan\n",
    "    mean_dest6 = np.mean(power_dest6) if power_dest6 else np.nan\n",
    "    sem_dest6 = sem(power_dest6) if power_dest6 else np.nan\n",
    "    \n",
    "    # Plot the comparison\n",
    "    fig, ax = plt.subplots(figsize=(3, 4))\n",
    "    ax.bar(1, mean_dest3, yerr=sem_dest3, color='blue', alpha=0.7, label='Going to Poster 3')\n",
    "    ax.bar(2, mean_dest6, yerr=sem_dest6, color='red', alpha=0.7, label='Going to Poster 6')\n",
    "    ax.set_xticks([1, 2])\n",
    "    ax.set_xticklabels(['Poster 3', 'Poster 6'])\n",
    "    ax.set_ylabel('Theta Power (μV²)')\n",
    "    ax.set_title(f'Channel {ch} - Start Poster {start_poster}')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Perform Welch's t-test if both groups have enough data\n",
    "    if len(power_dest3) > 1 and len(power_dest6) > 1:\n",
    "        t_stat, p_value = ttest_ind(power_dest3, power_dest6, equal_var=False)\n",
    "        ttest_results.append({\n",
    "            'channel': ch,\n",
    "            'start_poster': start_poster,\n",
    "            't_stat': t_stat,\n",
    "            'p_value': p_value\n",
    "        })\n",
    "        ax.text(1.5, max(mean_dest3, mean_dest6),\n",
    "                f't = {t_stat:.2f}\\np = {p_value:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Convert t-test results to DataFrame and save if needed\n",
    "ttest_results_df = pd.DataFrame(ttest_results)\n",
    "ttest_results_df.to_csv(\"ttest_results_start1_dest3_vs_6.csv\", index=False)\n",
    "print(\"T-test results saved to ttest_results_start1_dest3_vs_6.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### im not sure if i can just take the total theta power and just divide by the n?\n",
    "# ## TODO try getting the range of peaks from peak guess and then getting the peak theta power/n?\n",
    "# from scipy.stats import sem\n",
    "\n",
    "# theta_range = (2, 12)\n",
    "\n",
    "# for ch in channels_of_interest:\n",
    "#     fig, axes = plt.subplots(2, 3, figsize=(9, 6), sharex=True, sharey=True)\n",
    "#     axes = axes.flatten()\n",
    "\n",
    "#     for i, start_position in enumerate(np.sort(segments_df['start_position'].unique())):\n",
    "#         ax = axes[i]\n",
    "\n",
    "#         for j, cue_onset in enumerate(np.sort(segments_df['cue_onset'].unique())):\n",
    "#             filtered_df = segments_df.loc[\n",
    "#                 (segments_df['start_position'] == start_position) &\n",
    "#                 (segments_df['channel'] == ch) &\n",
    "#                 (segments_df['cue_onset'] == cue_onset)\n",
    "#             ]\n",
    "\n",
    "#             # Ensure there is PSD data to process\n",
    "#             if filtered_df.empty:\n",
    "#                 continue\n",
    "\n",
    "#             # Extract PSD and frequency data\n",
    "#             psd_list = filtered_df['psd'].tolist()\n",
    "#             freq_list = filtered_df['freq'].iloc[0][:150]  # Assuming freq is consistent\n",
    "#             psd_array = np.array(psd_list)\n",
    "\n",
    "#             # Get indexes for the theta band\n",
    "#             theta_indices = (freq_list >= theta_range[0]) & (freq_list <= theta_range[1])\n",
    "            \n",
    "#             theta_psd = psd_array[:, theta_indices]\n",
    "\n",
    "#             mean_psd = np.mean(theta_psd, axis=1)  # Mean power within the theta band for each trial\n",
    "#             mean_theta_power = np.mean(mean_psd)  # Mean across all trials\n",
    "#             sem_theta_power = sem(mean_psd)  # SEM across all trials\n",
    "\n",
    "#             # Plot mean and SEM\n",
    "#             ax.bar(j, mean_theta_power, yerr=sem_theta_power, label=f'Cue {cue_onset}', alpha=0.7)\n",
    "\n",
    "#         # Customize subplot\n",
    "#         ax.set_title(f'Start Position {start_position}')\n",
    "#         ax.set_xlabel('Cue Onset')\n",
    "#         ax.set_ylabel('Theta Power (u/V^2)')\n",
    "#         ax.legend(loc=\"lower behind\")\n",
    "\n",
    "#     # Adjust layout and add a main title\n",
    "#     plt.suptitle(f'Trial Averaged Theta Power for Channel {ch} (2-12 Hz)')\n",
    "#     plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the first, second, and third peaks\n",
    "first_peaks = segments_df['peak_freqs'].apply(lambda x: x[0] if len(x) > 0 else np.nan)\n",
    "second_peaks = segments_df['peak_freqs'].apply(lambda x: x[1] if len(x) > 1 else np.nan)\n",
    "third_peaks = segments_df['peak_freqs'].apply(lambda x: x[2] if len(x) > 2 else np.nan)\n",
    "\n",
    "# Drop NaN values for each peak set\n",
    "first_peaks = first_peaks.dropna()\n",
    "second_peaks = second_peaks.dropna()\n",
    "third_peaks = third_peaks.dropna()\n",
    "\n",
    "# Filter the peaks to include only values between 2 and 12 Hz\n",
    "first_peaks_filtered = first_peaks[(first_peaks >= 2) & (first_peaks < 12)]\n",
    "second_peaks_filtered = second_peaks[(second_peaks >= 2) & (second_peaks < 12)]\n",
    "third_peaks_filtered = third_peaks[(third_peaks >= 2) & (third_peaks < 12)]\n",
    "\n",
    "# Define bin edges from 2 to 12 in 1 Hz intervals\n",
    "bins = np.arange(2, 13, 1)  # This creates bins: [2-3), [3-4), ..., [11-12)\n",
    "\n",
    "# Plot distributions with filtered data\n",
    "plt.figure(figsize=(10, 5), dpi=150)\n",
    "\n",
    "# First peaks\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(first_peaks_filtered, bins=bins, alpha=0.7)\n",
    "plt.title('First Peaks Distribution')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(bins)  # Set x-axis ticks at 1 Hz intervals\n",
    "\n",
    "# Second peaks\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(second_peaks_filtered, bins=bins, alpha=0.7)\n",
    "plt.title('Second Peaks Distribution')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.xticks(bins)\n",
    "\n",
    "# Third peaks\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(third_peaks_filtered, bins=bins, alpha=0.7)\n",
    "plt.title('Third Peaks Distribution')\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.xticks(bins)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: i need to do anova on each starting position against cue poster. behind now its looking only at the starting position?\n",
    "\n",
    "# Define theta range\n",
    "theta_range = (2, 12)\n",
    "\n",
    "# Data structures to store ANOVA and Post-Hoc results\n",
    "anova_results = []\n",
    "posthoc_results = []\n",
    "\n",
    "for ch in channels_of_interest:\n",
    "    # Plot setup for each channel\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(12, 8), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, start_position in enumerate(np.sort(segments_df['start_position'].unique())):\n",
    "        ax = axes[i]\n",
    "        first_peak_by_cue = {}  # Store first peak frequencies grouped by cue onset\n",
    "        all_first_peaks = []\n",
    "        all_cue_labels = []\n",
    "\n",
    "        for j, cue_onset in enumerate(np.sort(segments_df['cue_onset'].unique())):\n",
    "            # Filter DataFrame for current start position, channel, and cue onset\n",
    "            filtered_df = segments_df.loc[\n",
    "                (segments_df['start_position'] == start_position) &\n",
    "                (segments_df['channel'] == ch) &\n",
    "                (segments_df['cue_onset'] == cue_onset)\n",
    "            ]\n",
    "\n",
    "            # Ensure there is peak frequency data to process\n",
    "            if filtered_df.empty or 'peak_freqs' not in filtered_df.columns:\n",
    "                continue\n",
    "\n",
    "            # Extract the first peak frequency\n",
    "            first_peaks = filtered_df['peak_freqs'].apply(lambda x: x[0] if len(x) > 0 else np.nan).dropna()\n",
    "\n",
    "            # Filter the peaks to include only values between 2 and 12 Hz (theta range)\n",
    "            first_peaks_filtered = first_peaks[(first_peaks >= theta_range[0]) & (first_peaks < theta_range[1])]\n",
    "\n",
    "            if first_peaks_filtered.empty:\n",
    "                continue\n",
    "\n",
    "            # Store first peak data for ANOVA\n",
    "            first_peak_by_cue[cue_onset] = first_peaks_filtered.values\n",
    "            all_first_peaks.extend(first_peaks_filtered.values)\n",
    "            all_cue_labels.extend([cue_onset] * len(first_peaks_filtered))\n",
    "\n",
    "            # Compute mean and SEM for plotting\n",
    "            mean_first_peak = np.mean(first_peaks_filtered)\n",
    "            sem_first_peak = sem(first_peaks_filtered)\n",
    "\n",
    "            # Plot mean and SEM\n",
    "            ax.bar(j + 1, mean_first_peak, yerr=sem_first_peak, label=f'Cue {cue_onset}', alpha=0.7)\n",
    "\n",
    "        # Customize subplot\n",
    "        ax.set_title(f'Start: Poster {start_position % 10}')\n",
    "        ax.set_xlabel('Cue Poster')\n",
    "        ax.set_ylabel('First Peak Frequency (Hz)')\n",
    "        ax.set_xticks(np.arange(1, len(np.unique(segments_df['cue_onset'])) + 1, 1))\n",
    "        ax.legend(loc=\"lower right\", fontsize='small')\n",
    "\n",
    "        # Perform ANOVA if there are at least two cue groups\n",
    "        if len(first_peak_by_cue) > 1:\n",
    "            f_stat, p_value = f_oneway(*first_peak_by_cue.values())\n",
    "            anova_results.append({\n",
    "                'channel': ch,\n",
    "                'start_position': start_position,\n",
    "                'f_stat': f_stat,\n",
    "                'p_value': p_value\n",
    "            })\n",
    "\n",
    "            # Perform post-hoc Tukey HSD if ANOVA is significant\n",
    "            if p_value < 0.05:\n",
    "                tukey_result = pairwise_tukeyhsd(endog=all_first_peaks,\n",
    "                                                 groups=all_cue_labels,\n",
    "                                                 alpha=0.05)\n",
    "\n",
    "                # Store post-hoc results\n",
    "                for res in tukey_result.summary().data[1:]:  # Skip header\n",
    "                    posthoc_results.append({\n",
    "                        'channel': ch,\n",
    "                        'start_position': start_position,\n",
    "                        'group1': res[0],\n",
    "                        'group2': res[1],\n",
    "                        'mean_diff': res[2],\n",
    "                        'p_adj': res[3],\n",
    "                        'lower': res[4],\n",
    "                        'upper': res[5],\n",
    "                        'reject': res[6]\n",
    "                    })\n",
    "\n",
    "    # Adjust layout and add main title\n",
    "    plt.suptitle(f'First Peak Frequency Across Cue Posters for Channel {ch}')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Convert ANOVA results to DataFrame\n",
    "anova_results_df = pd.DataFrame(anova_results)\n",
    "posthoc_results_df = pd.DataFrame(posthoc_results)\n",
    "\n",
    "# Save results to CSV files\n",
    "anova_results_df.to_csv(\"anova_results_first_peak.csv\", index=False)\n",
    "posthoc_results_df.to_csv(\"posthoc_results_first_peak.csv\", index=False)\n",
    "\n",
    "print(\"ANOVA results saved to anova_results_first_peak.csv\")\n",
    "print(\"Post-hoc Tukey results saved to posthoc_results_first_peak.csv\")\n",
    "\n",
    "# Display significant post-hoc results\n",
    "significant_posthoc = posthoc_results_df[posthoc_results_df['reject'] == True]\n",
    "print(\"\\nSignificant Post-Hoc Results: \\n\", significant_posthoc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhipp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
